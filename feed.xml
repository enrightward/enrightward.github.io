<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://enrightward.github.io/enrightward.github.io/</id><title>Logical Quantifier</title><subtitle>A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation.</subtitle> <updated>2021-03-17T06:29:11+01:00</updated> <author> <name>Stephen Enright-Ward</name> <uri>https://enrightward.github.io/enrightward.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://enrightward.github.io/enrightward.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en-US" href="https://enrightward.github.io/enrightward.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator> <rights> © 2021 Stephen Enright-Ward </rights> <icon>/enrightward.github.io/assets/img/favicons/favicon.ico</icon> <logo>/enrightward.github.io/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Convolutions of RVs — Part 2: A linear combination of uniform RVs</title><link href="https://enrightward.github.io/enrightward.github.io/posts/convolutions-part-2/" rel="alternate" type="text/html" title="Convolutions of RVs — Part 2: A linear combination of uniform RVs" /><published>2021-03-16T00:00:00+01:00</published> <updated>2021-03-17T06:28:43+01:00</updated> <id>https://enrightward.github.io/enrightward.github.io/posts/convolutions-part-2/</id> <content src="https://enrightward.github.io/enrightward.github.io/posts/convolutions-part-2/" /> <author> <name>Stephen Enright-Ward</name> </author> <category term="statistics" /> <category term="convolutions" /> <summary> 1. Introduction In the last post, we defined the convolution of the PDFs \(f_{X}\) and \(f_{Y}\) of two independent, continuous random variables \(X\) and \(Y\), and showed that it computed the PDF \(f_{X + Y}\) of the sum of \(X+Y\). Minor adaptations also yielded a method for computing \(f_{Y - X}\). We visualised both these PDFs in the case \(X, Y \sim U(0, 1)\), and saw that they differe... </summary> </entry> <entry><title>Convolutions of random variables — Part 1: Introduction</title><link href="https://enrightward.github.io/enrightward.github.io/posts/convolutions-part-1/" rel="alternate" type="text/html" title="Convolutions of random variables — Part 1: Introduction" /><published>2021-03-14T00:00:00+01:00</published> <updated>2021-03-14T00:00:00+01:00</updated> <id>https://enrightward.github.io/enrightward.github.io/posts/convolutions-part-1/</id> <content src="https://enrightward.github.io/enrightward.github.io/posts/convolutions-part-1/" /> <author> <name>Stephen Enright-Ward</name> </author> <category term="statistics" /> <category term="convolutions" /> <summary> 1. Introduction Suppose that \(X\) and \(Y\) are two continuous random variables. Given their PDFs PDFs \(f_{X}\) and \(f_{Y}\), how do you compute the \(f_{X + Y}\) of the sum of \(X+Y\)? In this post, we’ll define, compute examples of and prove some facts about the convolution \(f_{X} * f_{Y}\) of \(f_{X}\) and \(f_{Y}\), itself a PDF, and moreover equal to \(f_{X + Y}\), provided \(X\) an... </summary> </entry> <entry><title>Order statistics — Part 3: Proof of expectation formula for uniform RVs</title><link href="https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-3/" rel="alternate" type="text/html" title="Order statistics — Part 3: Proof of expectation formula for uniform RVs" /><published>2021-03-08T00:00:00+01:00</published> <updated>2021-03-11T09:41:19+01:00</updated> <id>https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-3/</id> <content src="https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-3/" /> <author> <name>Stephen Enright-Ward</name> </author> <category term="statistics" /> <category term="order statistics" /> <summary> 1. Introduction In the last post, we proved the following general formulae, after conducting some numerical experiments to gain intuition: \begin{align} F_{X_{(k)}}(x) &amp;amp;= \sum_{j=k}^{n} \binom{n}{j} F_{X}(x)^{j} (1 - F_{X}(x))^{n-j}, \newline f_{X_{(k)}}(x) &amp;amp;= k \binom{n}{k} f_{X}(x) \cdot F_{X}(x)^{k-1} \, (1 - F_{X}(x))^{n-k}, \newline \mathbb{E} \left \lbrack X_{(k)} \right \rbra... </summary> </entry> <entry><title>Order statistics — Part 2: General formulae for PDFs and expectations</title><link href="https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-2/" rel="alternate" type="text/html" title="Order statistics — Part 2: General formulae for PDFs and expectations" /><published>2021-03-07T00:00:00+01:00</published> <updated>2021-03-11T09:00:54+01:00</updated> <id>https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-2/</id> <content src="https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-2/" /> <author> <name>Stephen Enright-Ward</name> </author> <category term="statistics" /> <category term="order statistics" /> <summary> 1. Introduction In the last post, we defined the order statistics of a collection of iid random variables \(X_{1}, \ldots, X_{n}\), to try and answer questions like “What’s the expected value of \(\max( \{ X_{1}, \ldots, X_{n} \} )\)?”, or more generally “what is \(\mathbb{E}[(X_{(k)})]\)?”, where \(X_{(k)}\) is defined by the property: \begin{equation} X_{(1)} \le X_{(2)} \le \ldots \le X_... </summary> </entry> <entry><title>Order statistics — Part 1: Introduction and definitions</title><link href="https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-1/" rel="alternate" type="text/html" title="Order statistics — Part 1: Introduction and definitions" /><published>2021-03-05T00:00:00+01:00</published> <updated>2021-03-05T00:00:00+01:00</updated> <id>https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-1/</id> <content src="https://enrightward.github.io/enrightward.github.io/posts/order-statistics-part-1/" /> <author> <name>Stephen Enright-Ward</name> </author> <category term="statistics" /> <category term="order statistics" /> <summary> 1. Introduction On average, how tall is the tallest 8th grader in a class of 30 students, in the US? What is the value of the average winning bid in a Vickery Auction, where the highest bidder wins, but must pay only the second-highest bid? A common statistical approach here is: Assume the empirical data \(x_{1}, \ldots, x_{n}\) (heights, bids, etc.) are sampled from iid random variables... </summary> </entry> </feed>
